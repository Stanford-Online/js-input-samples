<problem>
<!-- This problem only logs student responses. It grades nearly anything as correct. -->

<script type="loncapa/python">
<![CDATA[
# The CDATA declaration lets us use less-than signs
# without edX thinking that we're starting an XML tag.

from python_lib import HXGraders

def answercheck(e, ans):

    options = {
        'min_length': 10   # This is the minimum length in characters of the response.
    }

    # This pulls from the python_lib.zip file in Files & Uploads.
    return HXGraders.journalingResponseGrader(ans, options)

]]>
</script>

<script type="text/javascript">
$(document).ready(function(){
	console.log('outer ready');
});

function logThatThing(ThatThing){
	console.log(JSON.stringify(ThatThing));
  // Call the edX logging code.
	Logger.log("harvardx.StudioAdv.text_logger", ThatThing);
}
</script>


<p>Put your prompt here.</p>

<!-- This will get turned into a rich text editor by hx-js. -->
<!-- Change the ID here and above if you have multiple on the same screen. -->
<div
  class="hx-editor"
  data-saveslot="journaling">
</div>

<customresponse cfn="answercheck">
  <jsinput title="Text Response Exercise"
    gradefn="journaling.getGrade"
    get_statefn="journaling.getState"
    set_statefn="journaling.setState"
    width="1"
    height="1"
    html_file="/static/journaling.html?saveslot=journaling"
    sop="false"/>
</customresponse>

<solution>
<div class="detailed-solution">
<p>Explanation</p>
<p>Questions should have explanations, or at least commentary.</p>
</div>
</solution>

</problem>
